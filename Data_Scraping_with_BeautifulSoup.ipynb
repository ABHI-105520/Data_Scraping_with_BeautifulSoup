{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importing Important Libraries\n",
    "###### 1. Request to get search results.<br>2. BeautifulSoup to scrap data.<br>3. Pandas data transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as re\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get Data\n",
    "###### We have to scrap from this site - https://www.architonic.com/en/accounts/representatives/10004/1<br>Headers is used to mimic a real browser to bypass scrap blocker or IP ban.<br>There are 3 pages containing result, so reading one by one and combined together.<br>If the Response code is 200, means the data read successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
    "html = \"\"\n",
    "\n",
    "#read all 3 pages\n",
    "for page in range(1, 4):\n",
    "    url = f\"https://www.architonic.com/en/accounts/representatives/10004/{page}\"\n",
    "    response = re.get(url,headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        html += response.text  #Append the page HTML content\n",
    "    else:\n",
    "        print(f\"Failed to fetch page {page}\")\n",
    "print(\"All pages read!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extract data\n",
    "###### If incase we request web multiple times, IP might get banned. So, i've extracted the data and exported in .html file so that we can perform data scraping without further issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"output.html\",\"w\",encoding=\"utf-8\") as f:\n",
    "    f.write(html)\n",
    "    print(\"Extract and Write Successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create soup object with BeautifulSoup\n",
    "\n",
    "###### We create an object from an HTML file for easy parsing and manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"output.html\",\"r\") as f:\n",
    "    soup=bs(f.read(),'html.parser')\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Scrap Data\n",
    "###### Using soup object, extracting required data like Profile Group, Profile and Location.<br>In Location, State and Country were kept together. So it has been separated in different column.<br>The extracted data is kept in dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data={\"Profile Group\":[],\"Profile\":[],\"State\":[],\"Country\":[]}\n",
    "\n",
    "#Profile Group\n",
    "pg=soup.find_all(class_=\"account-type small-12 columns\")\n",
    "for i in pg:\n",
    "    data[\"Profile Group\"].append(i.get_text())\n",
    "\n",
    "#Profile\n",
    "pf=soup.find_all(class_=\"account-title small-12 columns\")\n",
    "for i in pf:\n",
    "    data[\"Profile\"].append(i.get_text())\n",
    "\n",
    "#Location\n",
    "loc=soup.find_all(class_=\"account-info small-12 columns\")\n",
    "for i in loc:\n",
    "    ad=i.get_text().strip().split(\", \")\n",
    "    data[\"State\"].append(ad[0])\n",
    "    data[\"Country\"].append(ad[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Export Data\n",
    "###### The data in dict is transformed to pandas DataFrame and exported in excel format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame.from_dict(data)\n",
    "df.to_excel(\"Output.xlsx\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
